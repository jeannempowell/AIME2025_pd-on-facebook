{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependent libraries\n",
    "from constants import participants_token, facebook_files, file_data, aime_recordids_withfacebook, posts_token, all_posts\n",
    "from functions import pull_redcap_report, process_json_files, clean_and_deduplicate_text, safe_decode, redcap_upload\n",
    "import pandas as pd\n",
    "\n",
    "# Import data from REDCap to identify participants with Facebook data\n",
    "redcap_data = pull_redcap_report(participants_token, facebook_files)\n",
    "redcap_data = redcap_data[redcap_data['fb_data'] != ''] # Filter out record_ids withouth Facebook data\n",
    "redcap_data['record_id'] = redcap_data['record_id'].apply(str) # fix int/str issue\n",
    "redcap_data['your_posts_combined'] = redcap_data['your_posts_combined'].apply(str) # fix int/str issue\n",
    "\n",
    "redcap_data = redcap_data.reset_index()\n",
    "\n",
    "# Identify record_ids used in AIME2025 submission (all extant data as of January 2025)\n",
    "record_ids = aime_recordids_withfacebook\n",
    "\n",
    "# Extract text from JSON files affiliated with Posts, Comments and Reactions, and Groups exports\n",
    "# Save after each record_id because REDCap upload becomes tempermental when large\n",
    "for record_id in record_ids:\n",
    "    print(f'Now processing: Record ID: {record_id}')\n",
    "\n",
    "    # Generate text dataframe\n",
    "    df_text = pd.DataFrame(columns=['record_id', 'json_file', 'timestamp', 'title', 'text', 'group'])\n",
    "\n",
    "    # Pull JSON info for participant\n",
    "    record_data = redcap_data[redcap_data['record_id'] == record_id]\n",
    "    record_data = record_data.fillna(\"\")\n",
    "\n",
    "    # Extract Text\n",
    "    df_text = process_json_files(record_data, redcap_data, file_data, record_id, df_text)\n",
    "\n",
    "    # Deduplicate Text\n",
    "    df_text = clean_and_deduplicate_text(df_text)\n",
    "\n",
    "    # Ensure text is encoded as UTF-8\n",
    "    df_text['text'] = df_text['text'].apply(safe_decode)\n",
    "\n",
    "    # Assign participant_id to match record_id\n",
    "    df_text['participant_id'] = record_id\n",
    "\n",
    "    posts = pull_redcap_report(posts_token, all_posts)\n",
    "\n",
    "\n",
    "    if len(df_text) > 0 and int(df_text.loc[0, 'participant_id']) in posts['participant_id'].values:\n",
    "        print(f\"Participant ID '{record_id}' already exists in df_redcap. Not uploading data.\")\n",
    "\n",
    "    else: \n",
    "        if len(df_text) > 0:\n",
    "            # Set additional record_ids based on pre-existing data in REDCap\n",
    "            redcap_max = posts['record_id'].max()\n",
    "            if redcap_max == 1: redcap_max = 0 # Dealing with an empty dataframe\n",
    "            df_text['record_id'] = df_text.index + 1 + redcap_max\n",
    "\n",
    "            print(f'number of new entries: {len(df_text)}')\n",
    "            print(f'max record_id to be found in redcap after upload: {redcap_max + len(df_text)}')\n",
    "            response = redcap_upload(df_text)\n",
    "            print(f'Data from {record_id} successfully uploaded.')\n",
    "            print(f'Target length of Posts REDCap after upload attempt: {len(posts)+len(df_text)}')\n",
    "        else: print(f'Record ID {record_id} has no text to upload.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdfb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
